GPU架构基础：
Fermi第一次出现了两级cache的设计！

GPU 与CPU 的比较
(1) GPU Threads的生成代价小，是轻量级的线程；CPU Threads的生成代价大，是重量级的线程。
(2) 由于每一个Thread的生命周期长度是不相同的，Thread对Shared Memory的操作可能会导致读写的不一致，
	因此需要线程的同步，从而保证该block中所有线程同时结束。

CUDA：一种异构计算平台，API也有两种不同的层次，一种相对交高层，一种相对底层。
CUDA工具箱提供编译器，数学库，调试优化等工具。
NVIDIA为我们提供了：
Nvidia Nsight集成开发环境
CUDA-GDB 命令行调试器
性能分析可视化工具
CUDA-MEMCHECK工具
GPU设备管理工具

数据并行程序设计：
(1) 第一步就是把数据依据线程进行划分
	- 块划分，把一整块数据切成小块，每个小块随机的划分给一个线程，每个块的执行顺序随机
	- 周期划分，线程按照顺序处理相邻的数据块，每个线程处理多个数据块，比如我们有五个线程，
	  线程1执行块1，线程2执行块2…..线程5执行块5，线程1执行块6


1. nvidia-smi命令
(1) 第一行可以看到nvidia driver的版本和cuda 工具箱的版本
(2) 如果需要使用某个特定的GPU，则可以通过设置环境变量export CUDA_VISIBLE_DEVICES=1
(3) 

2. CUDA核函数需要用__global__修饰，返回类型必须是void，次序可随意。

3. 从Kepler架构开始，最大线程块1024，最大网格数2^31-1；
网格大小在x,y,z方向上最大值为2^31-1，65535,65535；线程块大小在x,y,z方向上最大值为1024，1024，64；

4. 几个影响GPU加速的关键因素
(1) 数据传输的比例
(2) 算术强度：计算工作量和访存工作量之比
	GPU的理论寄存器带宽 = 4 B * 4(每个FMA的操作数) / 2(每个FMA的浮点数操作次数) * 6.5 * 10^12/s = 52TB/s
	这里FMA指fused multiply-add指令，即涉及4个操作数和2个浮点数操作的d=axb+c
(3) 并行规模
	从Kepler到Volta架构，一个SM最多能reside线程数为2048，对于Turing，是1024。只有在GPU满负荷工作时，才能获得较高的加速比。

5. CUDA内存组织
全局内存：off-chip
常量内存：off-chip
纹理和surface内存：off-chip，是一种具有缓存的全局内存，因此访问速度比global memory要高，
				  但前提是一个warp中的线程都要读取相邻连续的内存数据。
局部内存：off-chip
共享内存：on-chip
寄存器内存：on-chip

6. SM的occupancy的相关指标
(1) 一个SM最多能拥有线程块个数N1 = 16(kepler and turing) or 32(maxwell, pascal and volta)
(2) 一个SM最多能拥有的线程个数N2 = 2048 or 1024(turing)
(3) 一个SM中最多能使用的register个数为 64K。

7. 全局内存的访问
(1) 对全局内存的访问将触发内存事物memory transaction，一次数据传输处理的数据量是32 bytes;
(2) 合并访问指的是一个warp对全局内存的一次访问请求产生的最少数量的数据传输方式；
(3) 合并度可以理解为是一种资源利用率，利用率越高，kernel函数中与全局访存有关的部分性能就更好，否则意味着对显存带宽的浪费；
(4) 所谓的一次数据传输，指的是将32字节的数据从全局通过L2 cache sector传输到SM上，
	一个float占4字节，所以一个warp访问需要request 128字节的数据，理想情况下，只需要触发128/32=4次L2cache的传输。
	那么非理想情况下呢，在一次数据传输中，从全局到L2cache的一片内存首地址必须是一个最小粒度32bytes的整数倍，
	如果一个warp请求的地址刚好是0~127这种，那就是合并访存了。
(5) 使用CUDA运行时API cudaMalloc分配的内存首地址至少是256字节的整数倍。
(6) 访问方式：对齐的合并访问，乱序的合并访问，不对齐的非合并访问，跨越式的非合并访问，广播式的非合并访问(适合使用常量内存)。

8. 共享内存的主要作用
(1) 减少全局内存的访问次数，实现高效的线程块内部的通信；
(2) 提高全局内存访问的合并度
(3) 使用dynamic共享内存：<<<grid, block,sizeof(real) * blockSize>>>以及extern __shared__ real smem[];
(3) 共享内存在物理上被分为32个同样宽度的能被同时访问的内存bank，除了Kepler架构，其他每个bank的宽度都是4 bytes

经验：
使用float数组时，共享内存并消除bank冲突的kernel最高效；
使用double数组时，仅使用全局内存且保证合并写入的kernel最高效。


使用统一内存编程：
(1) 统一内存是一种虚拟存储器，通过GPU和CPU各自内部集成的MMU实现。
(2) 统一内存之前，还有一种zero-copy，但不同的是，zero-copy只是用主机内存作为存储介质，而统一内存则将数据放在一个最合适的地方。
(3) 动态统一内存分配，cudaMallocManaged()；静态统一内存分配，__device__ __managed__ int a[100];
(4) 对于pascal以后的架构来说，cudaMallocManaged()的调用只代表成功预定了一段地址空间，
	而统一内存的实际分配发生在host或者device第一次访问预留的内存时。
(5) 要将host和device的内存都纳入统一内存，则需要用cudaMemPrefetchAsync()实现数据从host到device的迁移。
	同时也是避免频繁的缺页异常，保持数据的locality，它的作用就是在stream中将devPtr的统一内存缓冲区的内存迁移到设备中的内存区域。
(6) 注意：在pascal架构以后，使用统一内存时，可以不用cudaDeviceSynchronize同步操作了！

