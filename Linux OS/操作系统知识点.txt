操作系统原理：
进程和线程的管理，存储管理，设备管理，文件管理。
虚拟内存是一些系统页文件，存放在磁盘上，每个系统页文件大小为4K，物理内存也被分页，每个页大小也为4K

问：听过孤儿进程与僵尸进程么（提问概率：★★）
孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。
孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，
那么子进程的进程描述符等信息仍然保存在系统中，会对系统造成查询与内核占用负担，这种进程称之为僵尸进程

问：什么是原子操作，什么是临界区（提问概率：★★★★）
原子操作：就是计算机里不可拆分、不可中断的操作，要么执行完成，要么执行失败。
临界区：是一个访问共享资源的程序代码段，这个代码段同一时刻只能被一个线程锁访问。
当有一个线程进入临界区代码段时，其他线程或是进程必须等待。

说说线程跟进程的区别
每个线程有自己的堆栈。 进程间相互独立，同一进程的各线程间共享
- 线程是调度基本单位，进程是资源分配的基本单位
- 进程包含：程序段，数据段，PCB，进程状态PC，队列指针，优先级信息；
  线程包含一点必须资源：PC，一组register和栈；

fork的原理与实现
1.fork的作用就是克隆进程，进程就是运行的程序，在内存中运行的程序镜像；
2.进程拥有独立的地址空间，相同的两份代码；
3.fork就相当于同一个程序多次加载执行，因此在内存中产生了多个同名进程。
(超重要！！！)fork之后子进程和父进程的文件共享
- 当一个进程fork之后，整个进程表项被复制，包括所有的文件描述符。
- 但是文件表项并不会被复制。父进程和子进程共享相同的文件表项。
- 注意：文件的偏移量是储存在文件表项中，所以当一个进程读取了文件之后，另一个进程读取相同的文件会从上一个进程停止的地方开始读取。
- 子进程会复制父进程的几乎所有信息：子进程复制父进程用户空间所有数据；进程复制父进程内核空间PCB中绝大多数数据；
- 子进程复制父进程的数据段，BSS段，代码段，堆空间，栈空间，文件描述符，但是对于文件描述符关联的内核文件表项（即struct file结构体）则是采用共享的方式！
- 几个系统文件表条目可能对应于同一个内存索引节点表（不同进程打开同一个文件）。

文件描述符标志/文件表项
内核使用三种数据结构(进程表、文件表、v节点表结构)表示打开的文件，它们之间的关系决定了在文件共享方面一个进程对另一个进程可能产生的影响。
1. 每个进程在进程表中都有一个记录项，记录项中包含有一张打开文件描述符表。与每个文件描述符相关联的是：
  - 文件描述符标志(close-on-exec)（每个进程独有！）
  - 指向一个文件表项的指针
2. 内核为所有打开文件维持一张文件表项。每个文件表项包含：
  - 文件状态标志：读、写、添写、同步、非阻塞等（任何进程中的所有描述符都可指向同一个文件状态标志）
  - 当前文件偏移量
  - 指向该文件v节点表项的指针
  注意：fork后父子进程各自的每一个打开的文件描述符 share 同一个文件表项！
3. 每个打开文件(或设备)都有个v节点结构：
  - 文件类型
  - 对此文件进行各种操作的函数指针。
  
进程中fork和vfork的区别
fork和vfork都是调用函数显示进程id，但是fork是父子进程同时顺序进行，不会中断影响，而vfork是先执行子进程，当子进程结束之后才会执行父进程。

死锁：
1. 产生原因：竞争资源。系统资源不足和进程推进顺序不当。
2. 必要条件：互斥、不剥夺、请求与保持、环路等待。要产生死锁，4个条件缺一不可。比如要破坏环路等待：可以给系统资源分配编号排序申请。
3. 死锁解除：剥夺资源、撤销进程、进程回退。

哲学家就餐问题=>筷子是临界资源，不能被两个哲学家同时一起用，这样会造成死锁！
解决方案：
1. 最多只允许4个哲学家同时进餐
2. 仅当一个哲学家两边的筷子同时可用时，他才可以拿起筷子
3. 将哲学家编号，要求奇数号的先拿左边筷子，偶数号的先拿右边筷子

死锁的避免：银行家算法。
该方法允许进程动态地申请资源，系统在进行资源分配之前，先计算资源分配的安全性。
若此次分配不会导致系统从安全状态向不安全状态转换，便可将资源分配给进程；
否则不分配资源，进程必须阻塞等待。从而避免发生死锁。

进程间的通信IPC: 保持进程同步的方法？
原子操作atomic operation
信号量机制
自旋锁：对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。
但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，
调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，"自旋"一词就是因此而得名。
管程：利用 共享数据结构 抽象地表示系统中的共享资源，而把对该共享数据结构实施的操作定义为一组过程。

条件变量 是利用线程间共享的 全局变量 进行 同步 的一种机制

条件变量同锁一起使用使得线程可以以一种无竞争的方式等待任意条件的发生。
所谓无竞争就是，条件改变这个信号会发送到所有等待这个信号的线程。
而不是说一个线程接受到这个消息而其它线程就接收不到了。
条件变量用来自动阻塞一个线程，直到某特殊情况发生为止。通常条件变量和互斥锁同时使用。
条件变量使我们可以睡眠等待某种条件出现。

信号量：
信号量是一个计数器，可以用来控制多个进程对共享资源的访问。
它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源

问：常见进程通信方式与原理（提问概率：★★★★★）
进程间通信的本质是在内存开辟一块区域，然后两个进程通过这块内存进行信息交流。
- 管道（pipe）：半双工，用于父子进程通信，父进程在内核开辟一块缓冲区，得到两个文件描述符分别指向两端，子进程同理，然后父进程关闭读端进行写操作，子进程关闭写端进行读操作从而实现了两个进程的通信。
- 信号（signal）：类似于软中断，如果进程接受到了信号，就相当于发生了中断，这时候进程会切换到内核态去执行信号处理函数。进程之间可以通过系统调用互相发送信号，也可以在收到信号时做相应的回调。信号是类型是系统中事先定义好的，我们可以在发送某些特殊的信号加一些参数。
- 消息队列：系统提供的一种机制，可以从一个进程向另一个进程发送自定义的消息，这些消息会被放到一个特殊的内存区域，可以通过一个指针获取。多个消息的指针会构成一个队列，被内核管理着，其他进程可以从这个队列里面获取消息数据。
- 共享内存：通过系统调用开辟一块特殊的内存，然后映射到不同的进程上面，这样不同的进程在访问这一块内存的时候都可以像访问自己用户区内存一样，从而实现通信。
- 信号量：内核实现的一种特殊的对象，由操作系统赋予其控制进程状态的特性，信号量的值表示有几个任务可以访问该信号量所保护的共享资源。
- 套接字（socket)：常用于跨机器通信，属于应用层与传输层的一个连接媒介。

问：如何理解内核态与用户态（提问概率：★★★★）
- 在现在操作系统中，内存分为内核空间与用户空间,内核功能模块运行在内核空间，而应用程序运行在用户空间。
- 内核运行在最高级别（内核态），这个级别几乎可以使用处理器的所有资源，
- 应用程序运行在较低级别（用户态），在这个级别的用户不能对硬件进行直接访问以及对内存的非授权访问。
- 内核态和用户态有自己的内存映射，即自己的地址空间。
- 进程上下文和中断上下文就是完成这两种状态切换所进行的操作总称

/////////////////////////////////////////////////////////////////////

page cache的作用是什么呢？
内外存之间的缓存

page cache的一致性问题是如何解决的？
置脏页

页面置换算法有哪些？
（3）最近最久未使用置换算法LRU（Least Recently Used）：
该算法是选择最近最久未使用的页面予以淘汰，系统在每个页面设置一个访问字段，
用以记录这个页面自上次被访问以来所经历的时间T，当要淘汰一个页面时，选择T最大的页面。


线程间可以直接读写进程数据段（如全局变量）来进行通信
轮询——效率低，等待时间很长，CPU利用率不高。
中断——容易遗漏一些问题，CPU利用率高。

作业（或进程）的调度算法有哪些？

（1）先来先服务（FCFS，First-Come-First-Served）:
此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序来选择作业（或进程）。

（2）短作业优先（SJF,Shortest Process Next）：
这种调度算法主要用于作业调度，它从作业后备队列中挑选所需运行时间（估计值）最短的作业进入主存运行。

（3）时间片轮转调度算法（RR，Round-Robin）：
当某个进程执行的时间片用完时，调度程序便停止该进程的执行，并将它送就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程，在一给定的时间内，均能获得一时间片处理机执行时间。

（4） 优先权(Priority)调度算法: 
按照进程的优先权大小来调度，使高优先权进程得到优先处理的调度策略称为优先权调度算法。注意：优先数越多，优先权越小。


线程池整个项目中包括两个类：
Task类，用于描述执行一个任务的方法（一个函数）和执行这个任务所需要的参数（函数的参数）
ThreadPool类，在线程池中主要有两个队列，一个是Task类队列，用于存放要处理的任务。一个是线程池中存放线程的数组
1. 在线程池类中通过一个互斥锁（pthread_mutex_t类型变量）来实现线程池的线程安全性。
2. 在ThreadPool的构造函数中根据我们指定的个数使用new来动态创建线程数组。然后使用pthread_create为每个线程注册线程启动函数
3. 每个线程函数都是互斥的访问任务队列
4. 由于刚开始时没有任务到来，我们可以在线程函数中使用条件变量（pthread_cond_t）使得的线程都处于阻塞状态
5. 一旦有任务到来就使用pthread_cond_signal(&cond)来激活一个因为该条件而阻塞的线程
void * threadFunc(void *paramter)//线程中的线程启动函数，相当于执行任务的函数
{
    ...
    pthread_mutex_lock(&mutex);//加锁对任务队列互斥访问
    while(任务队列为空)
    {
            pthread_cond_wait(&cond, &mutex);
    }
    ....//获取任务
    pthread_mutex_unlock(&mutex);
    ....//执行任务
}
NOTE: 当程序执行到pthread_cond_wait函数内部时，首先会释放掉互斥锁，线程函数阻塞到这里，不再往下运行。
当有任务时会以“信号”的形式唤醒该线程函数，加锁并继续往下执行。
所以pthread_cond_wait函数=pthread_mutex_unlock+pthread_mutex_lock这两个函数功能。
向任务队列中添加任务的代码架构如下：
void addTast()
{
     pthread_mutex_lock(&mutex);//因为要互斥的访问任务队列，加锁
     ....//将任务添加到任务队列
     pthread_cond_signal(&cond);或者是pthread_cond_broadcast(&cond);//发送信号给一个因为该条件而阻塞的线程
     pthread_mutex_unlock(&mutex);//解锁
}

/////////////////////////////////////////////////////////////////////////

Linux 内存管理
操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。
Linux 系统中虚拟空间分布可分为用户态和内核态两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。
操作系统引入了虚拟内存，
进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

- 分段机制 把一个逻辑地址转换为线性地址
- 分页机制 把一个线性地址转换为物理地址

操作系统是如何管理虚拟地址与物理地址之间的关系？
主要有两种方式，分别是 内存分段 和 内存分页。

分段的优点：
- 解决了程序本身不需要关心具体的物理内存地址的问题；
- 内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据端、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。
分段的不足：
- 内存碎片的问题。（解决外部内存碎片的问题就是内存交换！）
- 内存交换的效率低的问题。（因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上）

内存碎片的问题共有两处地方：
- 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；
- 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；

分页的优点：
- 把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。
- 虚拟地址与物理地址之间通过 页表 来映射
- 采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。

分页机制下，虚拟地址和物理地址是如何映射的？
- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，
但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。
于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。

Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。
这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），
这种做法相当于屏蔽了处理器中的 逻辑地址 概念，段只被用于访问控制和内存保护。


CPU的缓存L1,L2,L3（spatial locality && temporal locality）
高速缓冲存储器Cache是位于CPU与内存之间的临时存储器，它的容量比内存小但交换速度快。
在Cache中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，
当CPU调用大量数据时，就可避开内存直接从Cache中调用，从而加快读取速度。
由此可见，在CPU中加入Cache是一种高效的解决方案，
这样整个内存储器（Cache+内存）就变成了既有Cache的高速度，又有内存的大容量的存储系统了。
Cache对CPU的性能影响很大，主要是因为CPU的数据交换顺序和CPU与Cache间的带宽引起的。

CPU缓存速度和内存速度差多少？
我们来简单地打个比方：如果CPU在L1一级缓存中找到所需要的资料要用的时间为3个周期左右，
那么在L2二级缓存找到资料的时间就要10个周期左右，L3三级缓存所需时间为50个周期左右；
如果要到内存上去找呢，那就慢多了，可能需要几百个周期的时间。


如何保证缓存和数据库的一致性？
方案一：更新缓存，更新数据库
这种方式可轻易排除，因为如果先更新缓存成功，但是数据库更新失败，则肯定会造成数据不一致。

方案二：更新数据库，更新缓存
这种缓存更新策略俗称双写，存在问题是：并发更新数据库场景下，会将脏数据刷到缓存
举例：如果在两个操作之间数据库和缓存又被后面请求修改，此时再去更新缓存已经是过期数据了！

方案三：删除缓存，更新数据库
存在问题：更新数据库之前，若有查询请求，会将脏数据刷到缓存
举例：如果在两个操作之间发生了数据查询，那么会有旧数据放入缓存。
该方案会导致请求数据不一致：
如果同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:
- 请求A进行写操作，删除缓存
- 请求B查询发现缓存不存在
- 请求B去数据库查询得到旧值
- 请求B将旧值写入缓存
- 请求A将新值写入数据库
上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据！

方案四：更新数据库，删除缓存
存在问题：在更新数据库之前有查询请求，并且缓存失效了，会查询数据库，然后更新缓存。
如果在查询数据库和更新缓存之间进行了数据库更新的操作，那么就会把脏数据刷到缓存
举例：如果在查询数据库和放入缓存这两个操作中间发生了数据更新并且删除缓存，那么会有旧数据放入缓存。
假设有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生:
- 缓存刚好失效
- 请求A查询数据库，得一个旧值
- 请求B将新值写入数据库
- 请求B删除缓存
- 请求A将查到的旧值写入缓存
如果发生上述情况，确实是会发生脏数据。但是发生上述情况有一个先天性条件，就是写数据库操作比读数据库操作耗时更短！
不过数据库的读操作的速度远快于写操作的，因此这一情形很难出现！

更新缓存还是删除缓存？
1.更新缓存缓存需要有一定的维护成本，而且会存在并发更新的问题
2.写多读少的情况下，读请求还没有来，缓存以及被更新很多次，没有起到缓存的作用
3.放入缓存的值可能是经过复杂计算的，如果每次更新，都计算写入缓存的值，浪费性能的
删除缓存优点：简单、成本低，容易开发；缺点：会造成一次cache miss
如果更新缓存开销较小并且读多写少，基本不会有写并发的时候可以才用更新缓存，否则通用做法还是删除缓存。

推荐方案
延迟双删，采用更新前后双删除缓存策略！
先淘汰缓存
再写数据库
休眠1秒，再次淘汰缓存
这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据！
问题及解法：
1、同步删除，吞吐量降低如何处理
将第二次删除作为异步的，提交一个延迟的执行任务
2、解决删除失败的方式：
添加重试机制，例如：将删除失败的key，写入消息队列；但对业务耦合有些严重；

注意：
关于缓存过期时间的问题
如果缓存设置了过期时间，那么上述的所有不一致情况都只是暂时的。
但是如果没有设置过期时间，那么不一致问题就只能等到下次更新数据时解决。
所以一定要设置缓存过期时间。


